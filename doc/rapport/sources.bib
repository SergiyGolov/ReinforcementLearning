@inproceedings{Kempka2016ViZDoom,
  author    = {Micha{\l} Kempka and Marek Wydmuch and Grzegorz Runc and Jakub Toczek and Wojciech Ja\'skowski},
  title     = {{ViZDoom}: A {D}oom-based {AI} Research Platform for Visual Reinforcement Learning},
  booktitle = {IEEE Conference on Computational Intelligence and Games},  
  year      = {2016},
  url       = {http://arxiv.org/abs/1605.02097},
  address   = {Santorini, Greece},
  Month     = {Sep},
  Pages     = {341--348},
  Publisher = {IEEE},
  Note      = {The best paper award}
}

@misc{vizDoomScenario,
  title = {{VizDoom} Scenarios},
  howpublished = {\url{https://github.com/mwydmuch/ViZDoom/tree/master/scenarios#defend-the-line}},
  note = {Accessed: 2019-01-25}
}

@misc{freecodecamp,
  title = {A Free course in Deep Reinforcement Learning from beginner to expert.},
  howpublished = {\url{https://simoninithomas.github.io/Deep_reinforcement_learning_Course/}},
  note = {Accessed: 2019-01-25}
}

@misc{layerGuide,
  title = {Beginners Ask “How Many Hidden Layers/Neurons to Use in Artificial Neural Networks?”},
  howpublished = {\url{https://towardsdatascience.com/beginners-ask-how-many-hidden-layers-neurons-to-use-in-artificial-neural-networks-51466afa0d3e
}},
  note = {Accessed: 2019-01-25}
}



@misc{sansFramework,
  title = {Deep Q learning with Doom},
  howpublished = {\url{https://gist.github.com/simoninithomas/7611db5d8a6f3edde269e18b97fa4d0c#file-deep-q-learning-with-doom-ipynb}},
  note = {Accessed: 2019-01-25}
}

@misc{dopamineDoc,
  title = {dopamine documentation},
  howpublished = {\url{https://github.com/google/dopamine/tree/master/docs}},
  note = {Accessed: 2019-01-25}
}


@misc{keras-rlDoc,
  title = {keras-rl documentation},
  howpublished = {\url{https://keras-rl.readthedocs.io/en/latest/}},
  note = {Accessed: 2019-01-25}
}

@misc{wikipediaRL,
  title = {Reinforcement Learning - Wikipedia},
  howpublished = {\url{https://en.wikipedia.org/wiki/Reinforcement_learning}},
  note = {Accessed: 2019-01-25}
}


@misc{andreykurenkov,
  title = {Andrey Kurenkov's website},
  howpublished = {\url{http://www.andreykurenkov.com}},
  note = {Accessed: 2019-01-25}
}
@misc{neuralnetworksanddeeplearning,
  title = {neuralnetworksanddeeplearning.com},
  howpublished = {\url{http://neuralnetworksanddeeplearning.com}},
  note = {Accessed: 2019-01-25}
}

@misc{vizDoomkeras-rl,
  title = {{VizDoom} keras-rl},
  howpublished = {\url{https://github.com/flyyufelix/ViZDoom-Keras-rl}},
  note = {Accessed: 2019-01-25}
}

@misc{tasfi2016PLE,
  author = {Tasfi, Norman},
  title = {PyGame Learning Environment},
  year = {2016},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/ntasfi/PyGame-Learning-Environment}}
}

@article{Rainbow,
  author    = {Matteo Hessel and
               Joseph Modayil and
               Hado van Hasselt and
               Tom Schaul and
               Georg Ostrovski and
               Will Dabney and
               Daniel Horgan and
               Bilal Piot and
               Mohammad Gheshlaghi Azar and
               David Silver},
  title     = {Rainbow: Combining Improvements in Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1710.02298},
  year      = {2017},
  url       = {http://arxiv.org/abs/1710.02298},
  archivePrefix = {arXiv},
  eprint    = {1710.02298},
  timestamp = {Mon, 13 Aug 2018 16:48:05 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1710-02298},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}